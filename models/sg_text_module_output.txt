Text Module Test Output
==================================================

1. Loading data using TextEmbeddingDataset...
   Found embeddings file at: data/spacegroup_embeddings_384d.npy
   ...Successfully loaded 230 samples.
   ...Detected 384 features per sample.

2. Creating an instance of the TextFeatureExtractor model.
TextFeatureExtractor(
  (extractor): Sequential(
    (0): Linear(in_features=384, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=256, out_features=128, bias=True)
    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
)

3. Creating a DataLoader to batch the real data.

4. Passing a batch of real data through the model.

--- Test Results ---
Input Data Shape: torch.Size([32, 384])
Output Data Shape: torch.Size([32, 128])
Input Data Range: [-0.1781, 0.2056]
Output Data Range: [-2.1455, 2.3281]

--- Embedding Statistics ---
Input Mean: -0.0002
Input Std: 0.0510
Output Mean: -0.0000
Output Std: 0.9974

✅ Test Successful: Model processed the text embeddings and produced the correct output shape.

5. Testing with different batch sizes...
   Batch size 1: torch.Size([1, 384]) → torch.Size([1, 128]) ✅
   Batch size 16: torch.Size([16, 384]) → torch.Size([16, 128]) ✅
   Batch size 64: torch.Size([64, 384]) → torch.Size([64, 128]) ✅
